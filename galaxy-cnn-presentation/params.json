{"name":"Galaxy Morphology Classification Using CNN","tagline":"Karen Loscocco, Yunqing (J.J.) Jia, Ammar Qaseem","body":"# Introduction\r\n\r\n## Motivation\r\n\r\nThe universe is approximately 13.8 billion years old, while the Earth has only been around for 4.54 billion years. As the universe continues to expand, questions remain about how galaxies formed and evolved. To solve this puzzle of the cosmic structure, understanding the distribution and types of galaxies as a function of their shapes and sizes is crucial. As the technology, specifically telescopes, for capturing such phenomena and returning images to scientists on Earth, improves, the dataset increases exponentially. Traditionally, galaxy identifications were achieved by crowdsourcing. However, as the datasets grow to the scale of hundreds of millions of galaxies, manual identification becomes less feasible. This project aims to analyze photos of galaxies and to train an algorithm that generates automated metrics and classifies them into two different classes, spiral and elliptical.\r\n\r\n![Galaxy Expansion](images/galaxy_expansion.png)\r\n\r\nFigure 1. Timeline of the Cosmos\r\n\r\n## Problem Definition & Project Scope\r\n\r\nGiven an already classified set of images, and the problem we are trying to solve is mapping JPEG images into two different categories. Since we are dealing with image data, the most obvious machine learning method to use was convolutional neural networks (CNN). However, this method does have its drawbacks, the most notorious one being the problem of overfitting, which is inevitable with the large number of parameters generated in the neural network. Dimensionality reduction methods such as principal component analysis (PCA) can be used to counteract such effects, and other machine learning methods such as ridge regression and random forest can be used to generate a baseline for us to evaluate our model’s performance. The data preprocessing and the different approaches are documented in detail in the Methodology section.\r\n\r\n# Methodology\r\n\r\n## Image Preprocessing\r\n\r\nThe dataset, acquired from [this Kaggle competition](https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge), includes 61,578 JPG images that are 424x424 pixels in size, as well as their probability distribution assignments based on 37 crowdsourced classifications.\r\n\r\nBy examining the dataset, most images had a large amount of black margins around the area of interest. Because of this, we decided to crop all images to 100x100 pixels and converted them to grayscale to reduce the computational cost. \r\n\r\n![Class 1](images/b_a_class1.jpeg) \r\n\r\n![Class 2](images/b_a_class2.jpeg) \r\n\r\n![Class 3](images/b_a_class3.jpeg)\r\n\r\nFigure 2. Original -> Cropped, Grayscale Images\r\n\r\nThe original 37 class probability assignments were based on the decision tree, which was comprised of 11 classification tasks, shown in Figure 3. All classes but those from the first task of the decision tree were composite probabilities, for the purpose of emphasizing the high-level, large-scale morphology categories.\r\n\r\nWe encountered difficulties enforcing composite constraints on the output layer of our algorithms, thus, we modified our objective by focusing on only the first task of the decision tree, which is composed of 3 classes, spiral, elliptical, and merging galaxies. The results from our algorithms build a foundation for future expansion of the objective. \r\n\r\n![Decision Tree & Task](images/decision_tree_task.png)\r\n\r\nFigure 3. Decision Tree & Decision Tasks\r\n\r\nWe then analyzed the distribution of probability assignments for the remaining 3 classes, and discovered that a large portion of data did not have a high confidence in one single category. We filtered out data points with a confidence below 0.8 and plotted a histogram (Figure 4). This procedure reduced our data set from 61,578 to 24,273 images.\r\n\r\n![Histogram of Probability Distributions for 3 Classes](images/3_class_prob_hist.jpeg)\r\n\r\nFigure 4. Histogram of Probability Distributions for 3 Classes\r\n\r\nWe also discovered that there are almost no sample with a highly confident assignment to the 3rd class. The 3rd class corresponded to merging galaxies, which are rare in this particular dataset. This led us to reduce our objective to a binary classification problem.\r\n\r\n![Histogram of Hard Assignment Distributions for 2 Classes](images/2_class_hard_hist.jpeg)\r\n\r\nFigure 5. Histogram of Hard Assignment Distributions for 2 Classes\r\n\r\n## Dimensionality Reduction\r\n\r\nWe attempted to run machine learning algorithms on the preprocessed images, but the results were only marginally better than the accuracy of random guessing. The computational cost was also very high, which made it difficult for us to experiment with different models and tweak parameters. To combat this challenge, we reduced the dimension of our dataset using Principal Component Analysis (PCA). The processed image originally had 10,000 components (100x100 pixels). After performing PCA, each data entry was reduced to only 17 components, which covered 95% of the variance. We then used the feature weights generated from PCA to reconstruct images to the cropped size so we can pass them back into our ML models. Figure 6 shows images before and after PCA, and Figure 7 shows the principal components projected into three dimensions. \r\n\r\n![Preprocessed Image PCA](images/Crop_PCA.jpg)\r\n\r\nFigure 6. Preprocessed -> PCA Reconstructed Image\r\n\r\n![Tensorboard Projector - PCA](images/PCA_final.gif) \r\n\r\nFigure 7. Tensorboard Projector - PCA\r\n\r\n![Tensorboard Projector - tSNE](images/T-SNE.gif)\r\n\r\nFigure 8. Tensorboard Projector - t-distributed Stochastic Neighbor Embedding\r\n\r\nWe also performed PCA on the original 424x424x3 images to validate that the preprocessed images preserved the most important features that best explained the variances in the data. An example of the resulting image is shown in Figure 8.\r\n\r\n![Full Size Image PCA](images/FS_PCA.jpg)\r\n\r\nFigure 9. Full Size Image -> PCA Reconstructed Image\r\n\r\n## Sprinkle in Some Machine Learning\r\n\r\n### Benchmarks\r\n\r\nTo set a baseline for the performance of our CNN, we fitted the data using Logistic Regression, Ridge Regression, and Random Forest. The dataset was split into 21,845 training points and 2,428 testing points. For the logistics regression, we used 'liblinear' as our solver, and for the ridge regression, we set alpha to 100. The confusion matrices and the accuracy scores for all three models are shown in the following figure.\r\n\r\n![Confusion Matrices for the Baseline Models](images/cm_baselines.png)\r\n\r\nFigure 10. Confusion Matrices for the Baseline Models\r\n\r\n### Convolutional Neural Network (CNN)\r\n\r\nThe best model we found is a variation of a model that was used to train the MNIST dataset. We tweaked the sequence of layers and their parameters, the architecture of our final model is as follows:\r\n\r\n![CNN Model Architecture](images/CNN_diagram.jpg)\r\n\r\nFigure 11. CNN Model Architecture\r\n\r\nThe input is presented to the model in the form of grayscale 100x100 image parts after dimensionality reduction (PCA). \r\n\r\nThe model had 5 layers, 2 convolutional layers and 2 dense layers. All convolutional layers included a ReLU activation to capture the nonlinearity (i.e. f(x) = max(x, 0)). The second convolutional layer is followed by 2x2 max-pooling. The number of nodes and the kernel size for each layer is labeled in Figure 12.\r\nWe trained the CNN with ADADELTA as the optimizer, which is an adaptive learning rate method for gradient descent. We defined our loss function to be categorical cross-entropy, which works well with hard assignments. And for our evaluation metrics, we computed the mean absolute error and the accuracy value on our training and validation data.\r\n\r\n# Results\r\n\r\nThe model achieved high accuracy: 98.77% for training and 95.74% validation.\r\n\r\n![Training and Validation Accuracy over 50 Epochs](images/cnn_acc.png)\r\n\r\nFigure 12. Training and Validation Accuracy over 50 Epochs \r\n\r\nThe mean absolute error and the accuracy value converged after 50 epochs. \r\n\r\n![Training and Validation Mean Absolute Error over 50 Epochs](images/cnn_mae.png)\r\n\r\nFigure 13. Training and Validation Mean Absolute Error over 50 Epochs \r\n\r\nThe validation loss started to increase again after about 15 epochs, which could be a sign of overfitting.\r\n\r\n![Training and Validation Loss over 50 Epochs](images/cnn_loss.png)\r\n\r\nFigure 12. Training and Validation Loss over 50 Epochs \r\n\r\n![Weight Distribution Histogram over 50 Epochs](images/weight_dist_hist.png)\r\n\r\nFigure 13. Weight Distribution Histogram over 50 Epochs\r\n\r\nTo be consistent with the evaluation metrics of our baseline models, we tested our model and obtained the following confusion matrix.\r\n\r\n![Confusion Matrix - CNN](images/cm_cnn.png)\r\n\r\nFigure 15. Confusion Matrix for CNN\r\n\r\n# Conclusion\r\n\r\nThe following figure lists the accuracy scores for all models generated in this project using various machine learning methods. \r\n\r\n| Model                | Testing Accuracy |\r\n| -----                | :--------------: |\r\n| Logistics Regression | 0.7727           |\r\n| Ridge Regression     | 0.7492           |\r\n| Random Forest        | 0.7537           |\r\n| **CNN**              | **0.9592**       |\r\n\r\nFigure 16. Comparison of Accuracy Scores for All Models\r\n\r\nThe trained Convolutional Neural Network yielded the highest testing accuracy score, 95.92%. CNN is once again proved to be a good machine learning method for processing image data.\r\n\r\n# Future Work\r\n\r\nTo further improve the machine learning model for this particular problem in the future, here are a few ideas one could pursue:\r\n* Use feature extraction to train the model on selected features rather than all the pixels in one image\r\n* Expand the problem to reproduce probability distribution for all 37 classes\r\n* Exploiting the invariances in images by randomly rotating, scaling, translating, and reflecting them\r\n\r\n\r\n# References\r\n\r\n - [1] Alex Krizhevsky et al., 2012. “ImageNet Classification with Deep Convolutional Neural Networks”\r\n\r\n - [2] H. Domínguez Spánchez et al., 2019. “Transfer learning for galaxy morphology from one survey to another”\r\n\r\n - [3] Kyle W. Willett et al., 2013. “Galaxy Zoo 2: detailed morphological classiﬁcations for 304,122 galaxies from the Sloan Digital Sky Survey”\r\n\r\n - [4] Sander Dieleman, 2014. \"My Solution for the Galaxy Zoo Challenge\"\r\n","note":"Don't delete this file! It's used internally to help with page regeneration."}